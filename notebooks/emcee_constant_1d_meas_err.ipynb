{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# from IPython.html.widgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "seaborn.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import emcee\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unknown constant intrinsic quantity $\\alpha$,\n",
    "measured via multiple noisy observations $\\{x_i\\}$;\n",
    "\n",
    "$$\n",
    "P(x_i~|~\\alpha,  \\sigma) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left[\\frac{-[x_i-\\alpha]^2}{2\\sigma^2}\\right]\n",
    "$$\n",
    "\n",
    "\n",
    "Multiplying these for all $i$ gives the likelihood:\n",
    "$$\n",
    "P(\\{x_i\\}~|~\\alpha, \\sigma) = (2\\pi\\sigma^2)^{-N/2} \\exp\n",
    "    \\left[- \\frac{1}{2\\sigma^2} \\sum_{i-1}^N [x_i - \\alpha]^2\n",
    "    \\right]\n",
    "$$\n",
    "so the likelihood can be rearranged as:\n",
    "$$\n",
    "ln\\left[P(\\{x_i\\}~|~\\alpha, \\sigma)\\right] =   -0.5*N*ln[2\\pi\\sigma^2] + \\left[- 0.5 \\sum_{i=1}^N [x_i - \\alpha]^2 / \\sigma^2 \\right]\n",
    "$$\n",
    "or indeed \n",
    "$$\n",
    "\\qquad =  - 0.5 \\sum_{i=1}^N \\left[ ln[2\\pi\\sigma^2] + [x_i - \\alpha]^2 / \\sigma^2  \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alpha = np.random.random()\n",
    "# alpha=0.95\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sigma = 0.2\n",
    "\n",
    "def log_likelihood(alpha, x,sigma):\n",
    "    return -0.5 * np.sum(np.log(2 * np.pi * sigma ** 2) + (x - alpha) ** 2 / sigma ** 2)\n",
    "#     return -0.5 * np.sum( ((x - alpha)/sigma)**2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def log_prior(alpha):\n",
    "    if 0. <= alpha < 1.:\n",
    "        return 0.0\n",
    "    return -np.inf\n",
    "\n",
    "def log_prob(alpha, x, sigma):\n",
    "    lp = log_prior(alpha)\n",
    "    if not np.isfinite(lp):\n",
    "        prob = -np.inf\n",
    "    else:\n",
    "        prob = lp+log_likelihood(alpha,x,sigma)\n",
    "    return prob#, alpha*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_samples = 7\n",
    "data = stats.norm.rvs(loc=alpha, scale=sigma, size=n_samples)\n",
    "# data = np.array([ 0.80008131,  0.942178  ])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.optimize as op\n",
    "neg_likelihood = lambda *args: -log_likelihood(*args)\n",
    "alpha_guess=0.\n",
    "result = op.minimize(neg_likelihood, alpha_guess, args=(data,sigma))\n",
    "result.x\n",
    "# result['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.nonparametric.kde import KDEUnivariate\n",
    "if len(data)>5:\n",
    "    dens = KDEUnivariate(data)\n",
    "    dens.fit()\n",
    "    plt.plot(dens.support,dens.density)\n",
    "#     plt.plot(dens.support,dens.cdf)\n",
    "# plt.plot(data,np.full_like(data, 0.1),'|', color='k', mew=2)\n",
    "seaborn.rugplot(data, \n",
    "                color='k'\n",
    "                )\n",
    "plt.axvline(alpha, c='r', label='Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.hist(data, normed=True)\n",
    "plt.axvline(alpha, c='r', label='Truth')\n",
    "plt.axvline(result.x, ls='--', label='MAP', c='y')\n",
    "pdf_support = np.linspace(alpha-3*sigma,alpha+3*sigma,100)\n",
    "plt.plot(pdf_support,stats.norm(loc=alpha,scale=sigma).pdf(pdf_support))\n",
    "if len(data)>5:\n",
    "    plt.plot(dens.support,dens.density)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ndim = 1  # number of parameters in the model\n",
    "nwalkers = 50  # number of MCMC walkers\n",
    "nburn = 100  # \"burn-in\" period to let chains stabilize\n",
    "nsteps = 500  # number of MCMC steps to take\n",
    "\n",
    "pos = [result.x + 1e-5*np.random.randn(ndim) for i in range(nwalkers)]\n",
    "# pos = [0.5 + 1e-4*np.random.randn(ndim) for i in range(nwalkers)]\n",
    "# set theta near the maximum likelihood, with \n",
    "# sampler.reset()\n",
    "# sampler = emcee.EnsembleSampler(nwalkers, ndim, log_likelihood, args=(data,))\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, log_prob, args=(data,sigma))\n",
    "sampler.reset()\n",
    "_=sampler.run_mcmc(pos, nsteps)\n",
    "for walker in sampler.chain:\n",
    "    plt.plot(walker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acorr = np.ceil(sampler.get_autocorr_time())\n",
    "acorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampler.acceptance_fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thinned_samples = sampler.chain[:,200::acorr,:]\n",
    "for walker in thinned_samples:\n",
    "    plt.plot(walker)\n",
    "print len(thinned_samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# samples = sampler.chain[:,150::,:].ravel()\n",
    "samples = thinned_samples.ravel()\n",
    "# plt.scatter(data, 2*np.ones_like(data))\n",
    "plt.hist(samples, normed=True, alpha=0.5)\n",
    "plt.axvline(alpha, c='r', ls=':',label='Truth')\n",
    "plt.axvline(result.x, ls='--', lw=3, label='MAP')\n",
    "# plt.ylim(0,5)\n",
    "plt.axvline(np.mean(samples), c='k', label='MC mean', ls='--')\n",
    "\n",
    "plt.plot(np.sort(samples), np.indices(samples.shape).ravel()/float(len(samples)), label='Cumulative Freq')\n",
    "# plt.plot(np.sort(samples), np.indices(samples.shape).ravel()/float(len(samples)))\n",
    "plt.axhline(0.16, ls=':')\n",
    "plt.axhline(0.5, ls=':')\n",
    "plt.axhline(0.84, ls=':')\n",
    "pdf_support = np.linspace(alpha-3,alpha+3,100)\n",
    "plt.plot(pdf_support,stats.norm(loc=alpha, scale=sigma).pdf(pdf_support), label=\"True dist\", ls='-.')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "# plt.ylim(0,1)\n",
    "plt.xlim(alpha-3*sigma,alpha+3*sigma)\n",
    "print alpha, np.mean(samples), result.x\n",
    "print (alpha - np.mean(samples))/sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
